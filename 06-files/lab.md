### Lab: Log Analysis and Report Generation

**Objective:** Practice reading, writing, and analyzing log files using Python's file-handling capabilities and standard library.

---

### Scenario:
You are a system administrator tasked with analyzing a log file generated by your server. The log file contains entries in the following format:

```
2024-12-04 10:23:45,INFO,Service started
2024-12-04 10:24:05,WARNING,High memory usage
2024-12-04 10:25:12,ERROR,Service failed
2024-12-04 10:26:30,INFO,Service restarted
```

Your tasks:
1. Parse the log file and extract entries based on severity levels (`INFO`, `WARNING`, `ERROR`).
2. Generate a report that counts the occurrences of each severity level.
3. Write the filtered logs and the report to separate output files.

---

### Lab Steps:

#### Step 1: Create a Log File
Write a Python script to create a sample log file named `server.log` with the content above. You could do this manually but nice to practice doing it with Python.

```python
with open("server.log", "w") as log_file:
    log_file.write("""2024-12-04 10:23:45,INFO,Service started
2024-12-04 10:24:05,WARNING,High memory usage
2024-12-04 10:25:12,ERROR,Service failed
2024-12-04 10:26:30,INFO,Service restarted
""")
```

#### Step 2: Read and Parse the Log File
Write a Python script to:
- Open the `server.log` file.
- Parse the log entries into separate lines and fields (`timestamp`, `severity`, and `message`).

```python
log_entries = []
with open("server.log", "r") as log_file:
    for line in log_file:
        timestamp, severity, message = line.strip().split(",")
        log_entries.append({"timestamp": timestamp, "severity": severity, "message": message})
```

#### Step 3: Filter Logs by Severity
Create functions to filter logs based on severity levels and save the filtered logs to separate files.

```python
def filter_logs_by_severity(log_entries, severity):
    return [entry for entry in log_entries if entry["severity"] == severity]

for severity in ["INFO", "WARNING", "ERROR"]:
    filtered_logs = filter_logs_by_severity(log_entries, severity)
    with open(f"{severity.lower()}_logs.txt", "w") as severity_file:
        for entry in filtered_logs:
            severity_file.write(f'{entry["timestamp"]},{entry["severity"]},{entry["message"]}\n')
```

#### Step 4: Generate a Report
Count the occurrences of each severity level and write the summary to a report file.

```python
severity_count = {}
for entry in log_entries:
    severity = entry["severity"]
    severity_count[severity] = severity_count.get(severity, 0) + 1

with open("log_report.txt", "w") as report_file:
    for severity, count in severity_count.items():
        report_file.write(f"{severity}: {count}\n")
```

---

### Expected Outputs:

1. **Filtered Logs:**
   - `info_logs.txt`
   - `warning_logs.txt`
   - `error_logs.txt`

2. **Report:** 
   A file named `log_report.txt` containing:

   ```
   INFO: 2
   WARNING: 1
   ERROR: 1
   ```

---

### Extensions (Optional):
1. Add a function to search for logs within a specific time range.
2. Generate a summary CSV file instead of plain text for the report.
3. Visualize the report data using a Python library like `matplotlib` or `pandas`.